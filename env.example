# 兩者擇一即可（建議先用 SUPER_MIND，因為它的 base_url 可能不支援 /responses）
OPENAI_API_KEY=
SUPER_MIND_API_KEY=

# base_url 決策：
# - 若有設定 SUPER_MIND_API_KEY：會使用 SUPER_MIND_BASE_URL（未設則程式內有預設）
# - 否則才會使用 OPENAI_API_KEY + OPENAI_BASE_URL
OPENAI_BASE_URL=https://api.openai.com/v1
SUPER_MIND_BASE_URL=https://space.ai-builders.com/backend/v1

# ----------------------------
# 額外 LLM（用於「Query 擴寫 / 背景壓縮」）的預設模型
# 你可以只改這行就切換（避免改程式碼）
#
# 例：
# GPT_MODEL=gpt-5.2
# GPT_MODEL=gpt-6
#
# 若 RAG_EXPAND_MODEL / RAG_COMPRESS_MODEL 未設定，會自動退回使用 GPT_MODEL
# 註：
# - supermind（AI Builders gateway）通常「不只」支援 gpt-5，也可能有 deepseek / gemini / grok 等模型 id
# - 你可以用後端 `/api/models` 列出可用模型，再把回傳的 model id 填到這裡
GPT_MODEL=supermind-agent-v1


# ----------------------------
# Query 擴寫（在進入 embedding / RAG 檢索前，先請外部大模型產生 tags/queries）
#
# 目的：提升檢索召回與命中率。此步驟的輸出（prompt、JSON、tags/queries、timings）會寫入同一個 session log。
RAG_EXPAND_ENABLE=1

# Query 擴寫用的模型（與壓縮模型分開）
# - 若留空，會用 GPT_MODEL
# - 支援用逗號提供多模型 fallback（建議）：
#   RAG_EXPAND_MODEL=supermind-agent-v1,deepseek,gpt-5
RAG_EXPAND_MODEL=supermind-agent-v1,deepseek,gpt-5

# 指定呼叫 API 形式：auto/chat/responses
# 建議用 auto：
# - 官方 OpenAI：通常優先走 /responses
# - 多數 gateway（含 supermind）：多半只有 /chat/completions，auto 會自動避開 /responses 404
RAG_EXPAND_API=auto

# 擴寫輸出 tokens 與溫度
RAG_EXPAND_MAX_TOKENS=300
RAG_EXPAND_TEMPERATURE=0.2

# 產生幾個「檢索用 queries」（不含原始問題；原始問題會永遠一起加入檢索）
RAG_EXPAND_NUM_QUERIES=6

# 若擴寫失敗是否要直接報錯（1=嚴格；0=失敗就退回用原始問題照常檢索）
RAG_EXPAND_STRICT=0

# 擴寫提示詞（建議用檔案路徑，方便放多行）
# - RAG_EXPAND_PROMPT_PATH：讀檔內容當作 system prompt（UTF-8）
RAG_EXPAND_PROMPT_PATH=system_prompt.md

# 讓輸出框只顯示「壓縮後的最小必要背景」（建議開）
RAG_REQUIRE_COMPRESSED_CONTEXT=1

# 壓縮用的 chat 模型名稱（請填你自己的供應商支援的名稱）
# 同樣支援逗號 fallback（建議）：
#   RAG_COMPRESS_MODEL=supermind-agent-v1,deepseek,gpt-5
RAG_COMPRESS_MODEL=supermind-agent-v1,deepseek,gpt-5

# 壓縮呼叫 API 形式：auto/chat/responses
RAG_COMPRESS_API=auto

# ----------------------------
# 推薦範本（直接複製貼到 .env，然後只改 key）
#
# SUPER_MIND_API_KEY=...
# SUPER_MIND_BASE_URL=https://space.ai-builders.com/backend/v1
#
# # 讓「擴寫」與「壓縮」都能在模型回空字串/不支援時，自動換下一個模型
# RAG_EXPAND_API=auto
# RAG_EXPAND_MODEL=supermind-agent-v1,deepseek,gpt-5
# RAG_COMPRESS_API=auto
# RAG_COMPRESS_MODEL=supermind-agent-v1,deepseek,gpt-5

# 控制壓縮長度（越小越精簡）
# 你的 log 顯示 gpt-5 可能把 token 花在內部推理，導致 message.content 變空字串；
# 先把上限拉高，讓它「有機會」真的把摘要吐出來。
RAG_COMPRESS_MAX_TOKENS=500

# 若壓縮摘要回空字串時（status=200 但 content=""），是否用「本機去重裁切」作為 fallback，避免整個 /api/prepare 直接 400
RAG_COMPRESS_FALLBACK_ON_FAILURE=1
RAG_COMPRESS_FALLBACK_MAX_CHARS=2200
RAG_COMPRESS_FALLBACK_PER_FRAGMENT_MAX_CHARS=900

# 是否把原始檢索片段也放進輸出框（預設不要）
RAG_PROMPT_INCLUDE_RAW_FRAGMENTS=0

# profile 資料來源（可填檔案或資料夾；若不填預設為 profile.md）
# 例如：
# - RAG_PROFILE_PATH=profile.md
# - RAG_PROFILE_PATH=profile/
RAG_PROFILE_PATH=personal_stable_MD/

# debug log 行為（只寫 session，不寫全域，避免不同 session 混在一起）：
# - logs/sessions/<session_id>/debug.log
RAG_SESSION_DEBUG_LOG=1

# 是否在 session JSON log 內包含「內容本體」：
# - 0（預設）：只保留除錯必需的結構/分數/來源/統計，question/prompt/片段文本會被打碼
# - 1：完整寫入（包含 question、檢索到的原文片段、組裝後 prompt、expand queries/tags 等）
# 開源/分享時強烈建議維持 0，避免你或貢獻者不小心把私密資料一起推到 GitHub。
RAG_LOG_INCLUDE_CONTENT=0

